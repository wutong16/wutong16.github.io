[{"authors":["admin"],"categories":null,"content":"Tong Wu is an incoming PostDoc at Stanford University, working with Prof. Gordon Wetzstein. She obtained her PhD degree in 2024 from Multi-Media Lab(MMLab) at CUHK, under the supervision of Prof. Dahua Lin. She also works closely with Prof. Ziwei Liu at NTU and previously served as a visiting student researcher at Stanford University with Prof. Gordon Wetzstein. She received her bachelor’s degree from the EE Department at Tsinghua University in 2020, where she worked with Prof. Yu Wang and Prof. Jiansheng Chen. Her research interests include 3D Vision and AIGC.\nNews\n[2024-09] Two papers accepted to NeurIPS 2024 (1 Main Track \u0026amp; 1 D\u0026amp;B Track). [2024-07] Two papers accepted to ECCV 2024. [2024-03] Three papers accepted to CVPR 2024 (1 Highlight). [2024-01] One paper accepted to ICLR 2024. [2023-08] One paper accepted to SIGGRAPH Asia 2023. [2023-07] We are organizing OmniObject3D Challenge, hosted by AI for 3D Content Creation Workshop on ICCV 2023. [2023-07] One paper accepted to ICCV 2023 (as Oral). [2023-06] Invited talk at 3D Scene Understanding Workshop on CVPR 2023. [2023-02] One paper accepted to CVPR 2023 (as Award Candidate, Top 12/9155). [2023-01] One paper accepted to ICLR 2023 (as Spotlight). [2021-09] Two papers accepted to NeurIPS 2021. [2021-07] We are organizing ICCV 2021 SenseHuman Workshop and MVP Challenge. [2021-06] Invited talks at RCV Workshop in CVPR 2021 and Techbeat. [2021-03] Two papers accepted to CVPR 2021 (both as Orals). [2020-07] Two papers accepted to ECCV 2020 (1 Spotlight). [2020-06] Happy graduation!! [2020-04] Awarded Hong Kong PhD Fellowship Scheme (HKPFS). ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Tong Wu is an incoming PostDoc at Stanford University, working with Prof. Gordon Wetzstein. She obtained her PhD degree in 2024 from Multi-Media Lab(MMLab) at CUHK, under the supervision of Prof.","tags":null,"title":"Tong WU 吴桐","type":"authors"},{"authors":null,"categories":null,"content":"","date":1733184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733184000,"objectID":"a9d430e5fb5a407e8805111b3c39bee4","permalink":"/publication/28_imagine360/","publishdate":"2024-12-03T00:04:30Z","relpermalink":"/publication/28_imagine360/","section":"publication","summary":"arXiv, 2024 *[Jing Tan](https://sparkstj.github.io/)\\*, [Shuai Yang](https://ys-imtech.github.io/)\\*, **Tong Wu**, [Jingwen He](https://scholar.google.com/citations?user=GUxrycUAAAAJ\u0026hl=zh-CN), [Yuwei Guo](https://guoyww.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Imagine360: Immersive 360 Video Generation from Perspective Anchor","type":"publication"},{"authors":null,"categories":null,"content":"","date":1733011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733011200,"objectID":"09047d6930e4523eac92767cc78be43d","permalink":"/publication/30_fiva/","publishdate":"2024-12-01T00:04:30Z","relpermalink":"/publication/30_fiva/","section":"publication","summary":"NeurIPS, 2024 (Datasets and Benchmarks Track) ***Tong Wu**, [Yinghao Xu](https://justimyhxu.github.io/), [Ryan Po](https://ryanpo.com/), [Mengchen Zhang](https://kszpxxzmc.github.io/), [Guandao Yang](https://www.guandaoyang.com/), [Jiaqi Wang](https://myownskyw7.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/), [Gordon Wetzstein](https://stanford.edu/~gordonwz/)*","tags":["Source Themes"],"title":"FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion Models","type":"publication"},{"authors":null,"categories":null,"content":"","date":1732838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1732838400,"objectID":"2c994339b3c964b670911a934e1125c1","permalink":"/publication/29_loki/","publishdate":"2024-11-29T00:04:30Z","relpermalink":"/publication/29_loki/","section":"publication","summary":"arXiv, 2024 *[Junyan Ye]()\\*, [Baichuan Zhou]()\\*, [Zilong Huang]()*, [Junan Zhang]()*, [Tianyi Bai](), [Hengrui Kang](), [Jun He](), [Honglin Lin](), [Zihao Wang](), **Tong Wu**, [Zhizheng Wu](), [Yiping Chen](), [Dahua Lin](), [Conghui He](), [Weijia Li]() *","tags":["Source Themes"],"title":"LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models","type":"publication"},{"authors":null,"categories":null,"content":"","date":1727913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727913600,"objectID":"d081ec4c1f9c97ff63d854529e53d664","permalink":"/publication/24_broadway/","publishdate":"2024-10-03T00:04:30Z","relpermalink":"/publication/24_broadway/","section":"publication","summary":"arXiv, 2024 *[Jiazi Bu]()\\*, [Pengyang Ling]()\\*, [Pan Zhang](), **Tong Wu**, [Xiaoyi Dong](), [Yuhang Zang](), [Yuhang Cao](), [Dahua Lin](), [Jiaqi Wang]()*","tags":["Source Themes"],"title":"BroadWay: Boost Your Text-to-Video Generation Model in a Training-free Way","type":"publication"},{"authors":null,"categories":null,"content":"","date":1725321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725321600,"objectID":"9212185d0124324a333ac682110ea113","permalink":"/publication/22_3dtopiaxl/","publishdate":"2024-09-03T00:04:30Z","relpermalink":"/publication/22_3dtopiaxl/","section":"publication","summary":"arXiv, 2024 *[Zhaoxi Chen](), [Jiaxiang Tang](), [Yuhao Dong](), [Ziang Cao](), [Fangzhou Hong](), [Yushi Lan](), [Tengfei Wang](), [Haozhe Xie](), **Tong Wu**, [Shunsuke Saito](), [Liang Pan](), [Dahua Lin](), [Ziwei Liu]()*","tags":["Source Themes"],"title":"3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion","type":"publication"},{"authors":null,"categories":null,"content":"","date":1722643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722643200,"objectID":"a5309a2c2ad55744b5cb961d4bd93124","permalink":"/publication/27_layerpano3d/","publishdate":"2024-08-03T00:04:30Z","relpermalink":"/publication/27_layerpano3d/","section":"publication","summary":"arXiv, 2024 *[Shuai Yang](https://ys-imtech.github.io/)\\*, [Jing Tan](https://sparkstj.github.io/)\\*, [Mengchen Zhang](https://kszpxxzmc.github.io/), **Tong Wu**, [Yixuan Li](https://yixuanli98.github.io/), [Gordon Wetzstein](https://stanford.edu/~gordonwz/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)","tags":["Source Themes"],"title":" LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1719792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792000,"objectID":"d36bb5268bc0b2135dad4183a14bb3c6","permalink":"/publication/26_taylor3d/","publishdate":"2024-07-03T00:04:30Z","relpermalink":"/publication/26_taylor3d/","section":"publication","summary":"arXiv, 2024 *[Zhangyang Qi](), [Yunhan Yang](), [Mengchen Zhang](), [Long Xing](), [Xiaoyang Wu](), **Tong Wu**, [Dahua Lin]()5, [Xihui Liu](), [Jiaqi Wang](), [Hengshuang Zhao]()*","tags":["Source Themes"],"title":"Tailor3D: Customized 3D Assets Editing and Generation with Dual-Side Images","type":"publication"},{"authors":null,"categories":null,"content":"","date":1717545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717545600,"objectID":"75f438b047343400a2de42cca7de83e8","permalink":"/publication/25_boostrap3d/","publishdate":"2024-06-05T00:04:30Z","relpermalink":"/publication/25_boostrap3d/","section":"publication","summary":"arXiv, 2024 *[Zeyi Sun](), **Tong Wu**, [Pan Zhang](), [Yuhang Zang](), [Xiaoyi Dong](), [Yuanjun Xiong](), [Dahua Lin](), [Jiaqi Wang]()*","tags":["Source Themes"],"title":"Bootstrap3D: Improving Multi-view Diffusion Model with Synthetic Data","type":"publication"},{"authors":null,"categories":null,"content":"","date":1717372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717372800,"objectID":"36e453d6d3ca714abcb04088b9bb6c0c","permalink":"/publication/23_motionclone/","publishdate":"2024-06-03T00:04:30Z","relpermalink":"/publication/23_motionclone/","section":"publication","summary":"arXiv, 2024 *[Pengyang Ling]()\\*, [Jiazi Bu]()\\*, [Pan Zhang](), [Xiaoyi Dong](), [Yuhang Zang](), **Tong Wu**, [Huaian Chen](), [Jiaqi Wang](), [Yi Jin]()*","tags":["Source Themes"],"title":"MotionClone: Training-Free Motion Cloning for Controllable Video Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1714003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714003200,"objectID":"9bf8be20f7ea65fa9a07b4119a203fba","permalink":"/publication/19_make_it_real/","publishdate":"2024-04-25T00:04:30Z","relpermalink":"/publication/19_make_it_real/","section":"publication","summary":"NeurIPS, 2024 *[Ye Fang](https://github.com/Aleafy)\\*, [Zeyi Sun](https://github.com/SunzeY)\\*, **Tong Wu**, [Jiaqi Wang](https://myownskyw7.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Gordon Wetzstein](https://stanford.edu/~gordonwz/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Make-it-Real: Unleashing Large Multimodal Model for Painting 3D Objects with Realistic Materials","type":"publication"},{"authors":null,"categories":null,"content":"","date":1709769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709769600,"objectID":"4c447ce5b772bc009d1798a6391f83b3","permalink":"/publication/31_omni6d/","publishdate":"2024-03-07T00:04:30Z","relpermalink":"/publication/31_omni6d/","section":"publication","summary":"ECCV, 2024 *[Mengchen Zhang](https://kszpxxzmc.github.io/), **Tong Wu**, [Tai Wang](https://tai-wang.github.io/), [Tengfei Wang](https://tengfei-wang.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1709424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709424000,"objectID":"0d2389ee206161030edbbf855aa1b3b3","permalink":"/publication/20_comboverse/","publishdate":"2024-03-03T00:04:30Z","relpermalink":"/publication/20_comboverse/","section":"publication","summary":"ECCV, 2024 *[Yongwei Chen](https://cyw-3d.github.io/)\\*, [Tengfei Wang](https://tengfei-wang.github.io/)\\*, **Tong Wu**, [Xingang Pan](https://xingangpan.github.io/), [Kui Jia](http://kuijia.site/), [Ziwei Liu](https://liuziwei7.github.io/)*","tags":["Source Themes"],"title":"ComboVerse: Compositional 3D Assets Creation Using Spatially-Aware Diffusion Guidance","type":"publication"},{"authors":null,"categories":null,"content":"","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709251200,"objectID":"67d54a347208577caa47cd24cb3d7e76","permalink":"/publication/21_3dtopia/","publishdate":"2024-03-01T00:04:30Z","relpermalink":"/publication/21_3dtopia/","section":"publication","summary":"arXiv, 2024 *, [Fangzhou Hong]()\\*, [Jiaxiang Tang]()\\*, [Ziang Cao]()\\*, [Min Shi]()\\*, **Tong Wu**, [Zhaoxi Chen](), [Shuai Yang](), [Tengfei Wang](), [Liang Pan](), [Dahua Lin](), [Ziwei Liu]()*","tags":["Source Themes"],"title":"3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors","type":"publication"},{"authors":null,"categories":null,"content":"","date":1704240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704240000,"objectID":"f31c75633a1fe9b7a21d446d1353fd45","permalink":"/publication/18_gpteval3d/","publishdate":"2024-01-03T00:04:30Z","relpermalink":"/publication/18_gpteval3d/","section":"publication","summary":"CVPR, 2024 ***Tong Wu**\\*, [Guandao Yang](https://www.guandaoyang.com/)\\*, [Zhibing Li](https://github.com/Lizb6626)\\*, [Kai Zhang](https://kai-46.github.io/website/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/), [Gordon Wetzstein](https://stanford.edu/~gordonwz/)*","tags":["Source Themes"],"title":"GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"523aadbbc8b978d0ba49ab0f8d641f58","permalink":"/publication/17_alphaclip/","publishdate":"2023-12-01T00:04:30Z","relpermalink":"/publication/17_alphaclip/","section":"publication","summary":"CVPR, 2024 *[Zeyi Sun](https://github.com/SunzeY)\\*, [Ye Fang](https://github.com/Aleafy)\\*, **Tong Wu**, [Pan Zhang](https://panzhang0212.github.io/), [Yuhang Zang](https://yuhangzang.github.io/), [Shu Kong](https://aimerykong.github.io/), [Yuanjun Xiong](http://yjxiong.me/), [Dahua Lin](http://dahua.site/), [Jiaqi Wang](https://myownskyw7.github.io/)*","tags":["Source Themes"],"title":"Alpha-CLIP: A CLIP Model Focusing on Wherever You Want","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"f4c47c2f4dba454d85f700258d9161b9","permalink":"/publication/15_gpt4point/","publishdate":"2023-12-01T00:03:30Z","relpermalink":"/publication/15_gpt4point/","section":"publication","summary":"CVPR, 2024 *[Zhangyang Qi](https://github.com/Qi-Zhangyang)\\*, [Ye Fang](https://github.com/Aleafy)\\*, [Zeyi Sun](https://github.com/SunzeY)\\*, [Xiaoyang Wu](https://xywu.me/), **Tong Wu**, [Jiaqi Wang](https://myownskyw7.github.io/)\\#, [Dahua Lin](http://dahua.site/), [Hengshuang Zhao](https://hszhao.github.io/)\\#*","tags":["Source Themes"],"title":"GPT4Point: A Unified Framework for Point-Language Understanding and Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1691107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691107200,"objectID":"cdc8008a41c54af720c62ca6d5a484c3","permalink":"/publication/14_iclr24_difftf/","publishdate":"2023-08-04T00:04:30Z","relpermalink":"/publication/14_iclr24_difftf/","section":"publication","summary":"ICLR, 2024 *[Ziang Cao](https://scholar.google.com/citations?user=L9tbNTsAAAAJ\u0026hl=zh-CN), [Fangzhou Hong](https://hongfz16.github.io/), **Tong Wu**, [Liang Pan](https://scholar.google.com/citations?user=lSDISOcAAAAJ\u0026hl=zh-CN), [Ziwei Liu](https://liuziwei7.github.io/)*","tags":["Source Themes"],"title":"Large-vocabulary 3d diffusion model with transformer","type":"publication"},{"authors":null,"categories":null,"content":"","date":1691020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691020800,"objectID":"6f5ad43702c6cc6da00b4ecde7219c0c","permalink":"/publication/13_siggraphasia2023_hyperdreamer/","publishdate":"2023-08-03T00:04:30Z","relpermalink":"/publication/13_siggraphasia2023_hyperdreamer/","section":"publication","summary":"SIGGRAPH Asia, 2023, conference track ***Tong Wu**\\*, [Zhibing Li](https://github.com/Lizb6626)\\*, [Shuai Yang](https://ys-imtech.github.io)\\*, [Pan Zhang](https://panzhang0212.github.io/), [Xingang Pan](https://xingangpan.github.io/), [Jiaqi Wang](https://myownskyw7.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a Single Image","type":"publication"},{"authors":null,"categories":null,"content":"","date":1674086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674086400,"objectID":"bc97b95a2e0721d087dbbe295c22b5e6","permalink":"/publication/11_cvpr2023_omniobject3d/","publishdate":"2023-01-19T00:04:30Z","relpermalink":"/publication/11_cvpr2023_omniobject3d/","section":"publication","summary":"CVPR, 2023 ** Best Paper Award Candidate, Top 12/9155** ***Tong Wu**, Jiarui Zhang, [Xiao Fu](https://fuxiao0719.github.io/), Yuxin Wang, [Jiawei Ren](https://jiawei-ren.github.io/), [Liang Pan](https://scholar.google.com/citations?user=lSDISOcAAAAJ\u0026hl=zh-CN), [Wayne Wu](https://wywu.github.io/), [Lei Yang](https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ\u0026hl=en), [Jiaqi Wang](https://myownskyw7.github.io/), [Chen Qian](https://scholar.google.com/citations?user=AerkT0YAAAAJ\u0026hl=zh-CN), [Dahua Lin](http://dahua.me/), [Ziwei Liu](https://liuziwei7.github.io/)*","tags":["Source Themes"],"title":"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"bac011a00d4740b5e4ff22c18211137c","permalink":"/publication/12_iccv2023_v3det/","publishdate":"2023-01-01T00:04:30Z","relpermalink":"/publication/12_iccv2023_v3det/","section":"publication","summary":"ICCV, 2023 **Oral presentation** [Jiaqi Wang*](https://myownskyw7.github.io/), [Pan Zhang*](https://panzhang0212.github.io/), [Tao Chu*](), [Yuhang Cao*](https://scholar.google.com/citations?user=sJkqsqkAAAAJ), Yujie Zhou, **Tong Wu**, Bin Wang, [Conghui He](https://scholar.google.com/citations?user=PopTv7kAAAAJ), [Dahua Lin](http://dahua.me/)","tags":["Source Themes"],"title":"V3Det: Vast Vocabulary Visual Detection Dataset","type":"publication"},{"authors":null,"categories":null,"content":"","date":1661731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661731200,"objectID":"9b4e4a95fc2aaef99d6b0953b551add9","permalink":"/publication/10_iclr2023_voxurf/","publishdate":"2022-08-29T00:04:30Z","relpermalink":"/publication/10_iclr2023_voxurf/","section":"publication","summary":"ICLR, 2023 **Spotlight** ***Tong Wu**, [Jiaqi Wang](https://myownskyw7.github.io/), [Xingang Pan](https://xingangpan.github.io/), [Xudong Xu](https://sheldontsui.github.io/), [Christian Theobalt](https://people.mpi-inf.mpg.de/~theobalt/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1632787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632787200,"objectID":"3d3773c90c286dca9089fa56abdabe1b","permalink":"/publication/7_neurips2021_dcd/","publishdate":"2021-09-28T00:04:30Z","relpermalink":"/publication/7_neurips2021_dcd/","section":"publication","summary":"NeurIPS, 2021 ***Tong Wu**, [Liang Pan](https://scholar.google.com/citations?user=lSDISOcAAAAJ), [Junzhe Zhang](https://junzhezhang.github.io/), [Tai Wang](https://tai-wang.github.io/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Density-aware Chamfer Distance as a Comprehensive Metric for Point Cloud Completion","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1632787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632787200,"objectID":"cfbe4e63580ce2b4c2f26fd6a522d227","permalink":"/publication/8_neurips2021_fadi/","publishdate":"2021-09-28T00:04:25Z","relpermalink":"/publication/8_neurips2021_fadi/","section":"publication","summary":"NeurIPS, 2021 *[Yuhang Cao](https://scholar.google.com/citations?user=sJkqsqkAAAAJ\u0026hl=zh-CN), [Jiaqi Wang](https://scholar.google.com.hk/citations?user=GDvt570AAAAJ\u0026hl=zh-CN), [Ying Jin](https://jin-ying.github.io/), **Tong Wu**, [Kai Chen](https://chenkai.site/), [Ziwei Liu](https://liuziwei7.github.io/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Few-Shot Object Detection via Association and DIscrimination","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1614643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614643200,"objectID":"3d78a8f9b75da9e03291f7bb331a9c92","permalink":"/publication/5_cvpr2021_adv-lt/","publishdate":"2021-03-02T00:03:00Z","relpermalink":"/publication/5_cvpr2021_adv-lt/","section":"publication","summary":"CVPR, 2021 **Oral presentation** ***Tong Wu**, [Ziwei Liu](https://liuziwei7.github.io/), [Qingqiu Huang](http://qqhuang.cn/), [Yu Wang](http://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Adversarial Robustness under Long-Tailed Distribution","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"7d688330e12615269db7fd738148646c","permalink":"/publication/6_cvpr2021_theoratical_adv/","publishdate":"2021-03-01T00:03:00Z","relpermalink":"/publication/6_cvpr2021_theoratical_adv/","section":"publication","summary":"CVPR, 2021 **Oral presentation** *[Zhaoyang Lyu](https://github.com/ZhaoyangLyu), [Minghao Guo](https://www.minghaoguo.com/), **Tong Wu**, [Guodong Xu](https://xuguodong.netlify.app/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Towards Evaluating and Training Verifiably Robust Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1604880000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604880000,"objectID":"5153cf06ed7fafd928b08036323aad98","permalink":"/publication/9_tpami2022_gaussian/","publishdate":"2020-11-09T00:04:25Z","relpermalink":"/publication/9_tpami2022_gaussian/","section":"publication","summary":"TPAMI, 2022 *[Weitao Wan](https://scholar.google.com/citations?hl=zh-CN\u0026user=xIdF_oMAAAAJ), [Jiansheng Chen](https://jschenthu.weebly.com/), Cheng Yu, **Tong Wu**, Yuanyi Zhong, [Ming-Hsuan Yang](https://scholar.google.com/citations?user=p9-ohHsAAAAJ\u0026hl=zh-CN)*","tags":["Source Themes"],"title":"Shaping Deep Feature Space towards Gaussian Mixture for Visual Classification","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1593820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593820800,"objectID":"cafbfc3e2eb3badc053a7569a496a114","permalink":"/publication/1_eccv2020_multi-lable_long-tail/","publishdate":"2020-07-03T00:03:00Z","relpermalink":"/publication/1_eccv2020_multi-lable_long-tail/","section":"publication","summary":"ECCV, 2020 **Spotlight** ***Tong Wu**, [Qingqiu Huang](http://qqhuang.cn/), [Ziwei Liu](https://liuziwei7.github.io/), [Yu Wang](http://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/), [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Distribution-Balanced Loss for Multi-Label Classification in Long-Tailed Datasets","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593734400,"objectID":"cd8e3d64e838fc7aac3e2624e4b0d0ce","permalink":"/publication/2_eccv2020_caption-supervised/","publishdate":"2020-07-01T00:02:00Z","relpermalink":"/publication/2_eccv2020_caption-supervised/","section":"publication","summary":"ECCV, 2020 *[Qingqiu Huang](http://qqhuang.cn/), [Lei Yang](https://github.com/yl-1993), [Huaiyi Huang](https://github.com/hahehi), **Tong Wu**, [Dahua Lin](http://dahua.me/)*","tags":["Source Themes"],"title":"Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model without Manual Annotation","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593475200,"objectID":"41313129373d1cfec9d67abbe8904d40","permalink":"/publication/4_arxiv2020_toyota/","publishdate":"2020-06-30T00:02:00Z","relpermalink":"/publication/4_arxiv2020_toyota/","section":"publication","summary":"Technique report, 2020 ***Tong Wu**, [Xuefei Ning](https://nicsefc.ee.tsinghua.edu.cn/people/xuefei-ning/), [Wenshuo Li](https://nicsefc.ee.tsinghua.edu.cn/people/wilson-lee/), [Ranran Huang](https://nicsefc.ee.tsinghua.edu.cn/people/ranran-huang/), [Huazhong Yang](https://scholar.google.com/citations?user=3m8I0XAAAAAJ\u0026hl=en), [Yu Wang](http://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/)*","tags":["Source Themes"],"title":"Physical Adversarial Attack on Vehicle Detector in the Carla Simulator","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"eb72692b24cdad9e12a96f60237b5682","permalink":"/publication/3_underreview_qr/","publishdate":"2019-08-26T00:02:00Z","relpermalink":"/publication/3_underreview_qr/","section":"publication","summary":"Technique report, 2019 ***Tong Wu**, [Jiansheng Chen](https://jschenthu.weebly.com/), [Yiqing Huang](https://scholar.google.com.hk/citations?user=MGMKjMoAAAAJ\u0026hl=zh-CN), [Yu Wang](http://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/)*","tags":["Source Themes"],"title":"Visual-friendly Aesthetic QR Code Generation using Image Style Transfer","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]